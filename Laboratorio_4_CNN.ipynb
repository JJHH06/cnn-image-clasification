{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 4 - Aprendizaje profundo para la clasificación de imágenes\n",
    "\n",
    "\n",
    "Siga las instrucciones en negritas para completar el laboratorio.\n",
    "\n",
    "------------\n",
    "\n",
    "## El reto\n",
    "\n",
    "**Su tarea es la de construir un clasificador de imágenes usando Keras (Tensorflow) y Redes Neuronales Convolucionales (CNN) para un conjunto de datos conocido como \"Fashion MNIST dataset\"\"\n",
    ". Este conjunto de datos incluye 10 etiquetas de diferentes tipos de ropa con imágenes de 28 by 28 *escalagris*. Hay un conjunto de datos de entrenamiento de 60,000 imágenes y un conjunto de datos de prueba de 10,000 imágenes.**\n",
    "\n",
    "    Etiqueta\tDescripción\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pablo Méndez 19195\n",
    "#### José Hurtarte 19707"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los datos\n",
    "\n",
    "**Tarea 1: Ejecute el siguiente código para descargar los datos usando Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_entreno, y_entreno), (X_prueba, y_prueba) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los Datos\n",
    "\n",
    "**TAREA 2: Utilice matplotlib para visualizar una imagen del conjunto de datos.  Puede ser cualquier imagen del conjunto de datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_entreno[666])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los Datos\n",
    "\n",
    "**TAREA 3: Normalice los datos X entreno y X prueba dividiendo por el valor máximo de los arreglos de las imágenes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 255)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_entreno_max = X_entreno.max()\n",
    "X_prueba_max = X_prueba.max()\n",
    "(X_entreno_max, X_prueba_max) # siempre va a ser 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_entreno_norm, X_prueba_norm) = (X_entreno / X_entreno_max, X_prueba / X_prueba_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_entreno_norm.max(), X_prueba_norm.max()) # siempre va a ser 1 por normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_entreno_norm[666])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TAREA 4: Cambie el formato de los arreglos X para que incluyan una 4rta dimensión del canal de color. Similar a lo que se hizo en clase para el conjunto de datos MNIST de números.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_entreno_norm.shape, X_prueba_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_entreno_norm = X_entreno_norm.reshape(X_entreno_norm.shape[0], 28, 28, 1)\n",
    "X_entreno_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prueba_norm = X_prueba_norm.reshape(X_prueba_norm.shape[0], 28, 28, 1)\n",
    "X_prueba_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TAREA 5: Convierta los valores de y_entreno y y_prueba para que estén \"one-hot encoded\" para poder hacer un análisis categórico con Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (10000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_entreno.shape, y_prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "(np.unique(y_entreno), np.unique(y_prueba)) # siempre van a ser 10 porque son 10 clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que son siempre valores del 1 al 10 por lo que los convertimos a categoricas para que tensorflow no haga una regresión rara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_entreno_cat = to_categorical(y_entreno)\n",
    "y_entreno_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prueba_cat = to_categorical(y_prueba)\n",
    "y_prueba_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración del Modelo\n",
    "\n",
    "**TAREA 6: Utilice Keras para crear un modelo que contenga, al menos, las siguientes capas (pero siéntase en libertad de experimentar):**\n",
    "\n",
    "* Capa \"2D Convolutional\", filtros = 32 y tamaño_kernel = (4, 4)\n",
    "* Capa de \"Pooling\"\"\n",
    " de tamaño = (2, 2)\n",
    "\n",
    "* Capa de Aplanado\n",
    "* Capa Densa (128 unidades, pero siéntase en libertad de \"jugar\"con este valor), activación RELU\n",
    "\n",
    "* Una capa Final Densa de 10 unidades con activación softmax\n",
    "\n",
    "**Luego compile el modelo con estos parámetros: loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo\n",
    "**TAREA 6: Entrene/Ajuste el modelo con el conjunto X_entreno set. La cantidad de épocas le queda a Ud determinar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1802 - acc: 0.9365\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1679 - acc: 0.9395\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1579 - acc: 0.9439\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1502 - acc: 0.9469\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1427 - acc: 0.9496\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1397 - acc: 0.9523\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1312 - acc: 0.9551\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1274 - acc: 0.9559\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1238 - acc: 0.9582\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1201 - acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c18a60e400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del Modelo\n",
    "\n",
    "**TAREA 7: Muestre los valores de [accuracy, precision, recall, f1-score] que logró el modelo con el conjunto de datos X_prueba data set. Tenga en mente que hay múltiples formas de hacer esto.  Sin embargo, le recomendamos que utilice el mismo procedimiento usado mencionado en la parte de intuición, en clase.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.88      0.83      0.85      1000\n",
      "          3       0.91      0.91      0.91      1000\n",
      "          4       0.83      0.88      0.85      1000\n",
      "          5       0.97      0.98      0.98      1000\n",
      "          6       0.73      0.76      0.74      1000\n",
      "          7       0.95      0.97      0.96      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.98      0.94      0.96      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gran trabajo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "347a625715fe29511df74443d0ac60b514ce17bf8af058876f43cde387af9535"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
